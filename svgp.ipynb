{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "advised-leisure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acceptable-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import tqdm.notebook\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from gpytorch import Module\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impressed-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting datasets\n",
    "datasets = ['boston', 'concrete', 'yacht', 'wine']\n",
    "\n",
    "# data(d), original features(x_), original target(y_), scale of test split(s), low of test split(l), normalized features(x), normalized target(y)\n",
    "d, x_, y_, s, l, x, y = {}, {}, {}, {}, {}, {}, {}\n",
    "\n",
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    d[i] = pd.read_csv('data_vrbound/{}/data.txt'.format(datasets[i]), \n",
    "                       delim_whitespace=True, header=None).dropna().astype(float)\n",
    "    x_[i] = d[i].iloc[:,0:-1]\n",
    "    y_[i] = d[i].iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dependent-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scenic-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0782,  1.5890,  1.2293,  0.4232,  1.2083,  1.3469],\n",
       "         [ 0.0782,  0.2379, -0.0514, -1.6154,  1.7331,  1.5939],\n",
       "         [ 0.0120,  0.4558, -1.7324,  0.0444, -1.8193, -0.8754],\n",
       "         ...,\n",
       "         [ 0.0120,  0.1943, -1.8124, -1.7237, -0.2450, -1.1223],\n",
       "         [ 1.6009,  1.5890, -0.0514,  0.5495, -0.2450,  1.1000],\n",
       "         [ 0.0782,  0.0636, -0.0514,  2.5521, -1.8193,  0.6062]]),\n",
       " tensor([[ 0.0120,  0.1943, -1.8124, -1.7237, -0.2450, -0.8754],\n",
       "         [ 0.0782,  1.5890, -1.8124,  0.5315, -1.9404,  0.8531],\n",
       "         [ 1.6009,  1.5890, -0.0514,  0.5495, -0.2450, -0.6285],\n",
       "         [-1.7094,  1.5890, -0.0514,  0.5495, -0.2450, -1.6162],\n",
       "         [ 1.6009, -1.4619, -0.0514, -0.3345, -0.2450,  0.1123],\n",
       "         [ 1.6009,  0.0636,  1.2293,  0.0083,  1.2083,  0.8531],\n",
       "         [ 0.0782, -1.4619, -0.1315, -0.4608, -0.2046, -1.3692],\n",
       "         [ 1.6009,  1.5890, -0.0514,  0.5495, -0.2450, -0.8754],\n",
       "         [-1.7094, -1.4619, -0.0514, -0.3345, -0.2450,  0.3592],\n",
       "         [ 0.0120,  0.4558, -1.7324,  0.0444, -1.8193, -1.1223],\n",
       "         [ 0.0782, -1.4619, -0.1315, -0.4608, -0.2046, -0.1346],\n",
       "         [-1.7094,  0.0636,  1.2293,  0.0083,  1.2083, -0.3815],\n",
       "         [ 1.6009,  1.5890, -0.0514,  0.5495, -0.2450,  1.3469],\n",
       "         [ 0.0782,  1.5890, -1.8124,  0.5315, -1.9404,  1.1000],\n",
       "         [ 0.0782,  1.5890,  1.2293,  0.4232,  1.2083, -0.8754],\n",
       "         [ 0.0782,  1.5890, -1.8124,  0.5315, -1.9404, -0.8754],\n",
       "         [ 0.1444, -0.7645, -0.0514,  0.3511, -0.5679,  0.3592],\n",
       "         [ 1.6009,  0.0636,  1.2293,  0.0083,  1.2083, -0.8754],\n",
       "         [ 1.6009,  1.5890, -0.0514,  0.5495, -0.2450, -0.1346],\n",
       "         [ 0.0782,  0.2379, -0.0514, -1.6154,  1.7331, -0.6285],\n",
       "         [ 0.0782,  1.5890, -1.8124,  0.5315, -1.9404,  1.5939],\n",
       "         [ 0.0782,  0.1943, -0.0514,  0.0985, -0.1642,  1.1000],\n",
       "         [-1.7094,  0.0636,  1.2293,  0.0083,  1.2083, -1.3692],\n",
       "         [ 1.6009,  0.0636,  1.2293,  0.0083,  1.2083,  1.1000],\n",
       "         [ 0.0782, -1.4619, -1.8124, -2.0304, -0.2450,  0.1123],\n",
       "         [ 0.0782, -1.4619, -1.8124, -2.0304, -0.2450,  1.3469],\n",
       "         [ 0.0120,  0.9352, -0.0514, -0.1721,  0.4413, -1.1223],\n",
       "         [ 0.0782, -0.0672,  1.3894,  1.8304, -0.1642, -0.3815],\n",
       "         [ 0.1444, -0.7645, -0.0514,  0.3511, -0.5679, -0.3815],\n",
       "         [ 0.0782, -0.0672,  1.3894,  1.8304, -0.1642, -1.3692],\n",
       "         [ 0.0782,  0.1943, -0.0514,  0.0985, -0.1642,  1.3469]]),\n",
       " tensor([ 1.3748,  2.6790, -0.6334, -0.6751,  2.9161, -0.1704, -0.5917, -0.6783,\n",
       "          0.2027, -0.5533, -0.6217, -0.4107,  1.7401, -0.4927, -0.0193, -0.1235,\n",
       "         -0.6054, -0.4068, -0.6171,  2.6914, -0.5233, -0.1711,  2.5058,  0.0588,\n",
       "         -0.2277, -0.5090, -0.6698,  1.7883, -0.6861, -0.6868, -0.1899, -0.5702,\n",
       "          2.1959, -0.5097, -0.6204, -0.5663, -0.4491, -0.5136, -0.5917, -0.6164,\n",
       "          2.7617, -0.5865,  0.6995, -0.3931,  0.6351, -0.6842,  0.1128, -0.6510,\n",
       "          0.3681, -0.6685,  0.7380, -0.6809, -0.1548,  1.0863, -0.4432, -0.5754,\n",
       "         -0.6731,  0.1578,  1.2654, -0.6920,  0.7067,  0.1337, -0.4693, -0.5025,\n",
       "         -0.3391,  1.4698,  0.2248, -0.6829, -0.4035, -0.6151, -0.5904, -0.6913,\n",
       "         -0.4276, -0.6282, -0.6705, -0.6516, -0.5253, -0.3169, -0.6887, -0.5064,\n",
       "          0.0972, -0.6783,  2.5709, -0.2472,  0.6175, -0.4257, -0.6887,  0.1369,\n",
       "         -0.5227, -0.6692, -0.6431, -0.3690, -0.4113,  1.7772, -0.6881, -0.6379,\n",
       "         -0.6640,  2.5853, -0.6913,  0.6676, -0.5097, -0.5676, -0.5526, -0.5644,\n",
       "         -0.4198, -0.4419, -0.4341, -0.2290, -0.2831,  0.1434, -0.6106, -0.4237,\n",
       "          0.1194, -0.6907, -0.5657,  1.2908,  0.2151,  1.4640, -0.4797, -0.6308,\n",
       "          2.5853,  0.7067,  0.8773,  0.0868,  1.4197, -0.3058,  0.6351, -0.6132,\n",
       "         -0.6438, -0.6679, -0.1326, -0.6047,  3.3706, -0.6809, -0.5657, -0.6275,\n",
       "         -0.6451, -0.6757, -0.4999, -0.6581,  2.9441, -0.0786, -0.5318, -0.1287,\n",
       "         -0.6646, -0.5748, -0.3032, -0.6633,  1.5180, -0.3508, -0.1763, -0.1834,\n",
       "          0.8662, -0.6887, -0.3645, -0.6809, -0.6711, -0.6106,  2.3854,  1.7244,\n",
       "          1.5525, -0.2902, -0.6047,  0.1395,  0.8780, -0.6894, -0.6718, -0.3417,\n",
       "          1.5578,  0.8395, -0.1033,  0.6494,  1.6268,  2.6230,  2.3750,  2.5286,\n",
       "          1.4119, -0.6711, -0.6881, -0.6334,  0.9457, -0.5650, -0.3332, -0.6829,\n",
       "         -0.5422, -0.5233, -0.6822, -0.5852, -0.6191,  0.2991, -0.5663, -0.1424,\n",
       "         -0.1815, -0.2258, -0.5735, -0.6633, -0.6633, -0.6529,  0.1434, -0.5240,\n",
       "         -0.2049, -0.6620, -0.4537, -0.4706, -0.6731, -0.1711, -0.6777,  0.6748,\n",
       "         -0.6933, -0.5194, -0.6047, -0.4061, -0.6230, -0.3150, -0.5735, -0.6444,\n",
       "          3.2683, -0.6243, -0.6842, -0.6484, -0.2310,  0.0829, -0.3312, -0.6086,\n",
       "          0.2782,  1.6151,  2.8373, -0.6770, -0.6868,  2.8985, -0.6132, -0.5044,\n",
       "          2.6771, -0.6679,  0.6793, -0.6874, -0.3560, -0.6829,  0.5550,  1.5858,\n",
       "         -0.5338, -0.6711, -0.6431, -0.4341, -0.5884, -0.6575, -0.2140, -0.6379,\n",
       "         -0.4960, -0.5604,  2.0259,  2.9825, -0.6764, -0.3938, -0.4491, -0.6822,\n",
       "         -0.6484, -0.6529, -0.6008,  1.5180, -0.3560, -0.6614, -0.6835, -0.6555,\n",
       "          0.2001,  0.1135, -0.6835,  2.6595, -0.6770, -0.6425, -0.6197, -0.4244,\n",
       "         -0.4927, -0.6340, -0.6659,  0.8135, -0.1567]),\n",
       " tensor([ 0.6900, 12.2700,  1.3000,  0.0600,  3.7000, 14.2400,  0.2300,  0.7300,\n",
       "          5.0700,  0.6500,  2.2800,  1.7600, 34.6200, 19.5900,  0.7300,  0.6400,\n",
       "          4.8300,  0.8300,  3.3500,  1.0600, 46.6600, 20.1100,  0.2400, 23.0500,\n",
       "          2.7300, 41.3400,  0.6400,  2.2300,  1.7600,  0.4400, 32.7500]),\n",
       " 10.657003610108303,\n",
       " 15.357361334179048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_data(x, y, test_split, seed, norm=True):\n",
    "    \n",
    "    x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=test_split, random_state=seed)\n",
    "    \n",
    "    mean_y_train = y_train.mean()\n",
    "    std_y_train = y_train.std()\n",
    "    \n",
    "    if norm:\n",
    "        x_train = pd.DataFrame(x_train.values)\n",
    "        x_test = pd.DataFrame(x_test.values)\n",
    "        y_train = pd.DataFrame(y_train.values.reshape(-1,1))\n",
    "        y_test = pd.DataFrame(y_test.values.reshape(-1,1))\n",
    "\n",
    "        mean_x_train = x_train.mean()\n",
    "        std_x_train = x_train.std()\n",
    "        std_x_train[std_x_train==0] = 1\n",
    "        x_train = (x_train - mean_x_train) / std_x_train\n",
    "        x_test = (x_test - mean_x_train) / std_x_train\n",
    "        y_train = (y_train - mean_y_train) / std_y_train\n",
    "\n",
    "    else:\n",
    "        x_train = pd.DataFrame(x_train.values)\n",
    "        x_test = pd.DataFrame(x_test.values)\n",
    "        y_train = pd.DataFrame(y_train.values.reshape(-1,1))\n",
    "        y_test = pd.DataFrame(y_test.values.reshape(-1,1))\n",
    "        scale = 1\n",
    "        low = 0\n",
    "\n",
    "    list_of_tensors = [torch.tensor(x_train[i], dtype=torch.float32) for i in x_train]\n",
    "    train_x = torch.stack(list_of_tensors)\n",
    "    train_x = torch.transpose(train_x, 0, 1)\n",
    "\n",
    "    list_of_tensors = [torch.tensor(x_test[i], dtype=torch.float32) for i in x_test]\n",
    "    test_x = torch.stack(list_of_tensors)\n",
    "    test_x = torch.transpose(test_x, 0, 1)\n",
    "\n",
    "    train_y = torch.tensor(y_train[0], dtype=torch.float32)\n",
    "    test_y = torch.tensor(y_test[0], dtype=torch.float32)\n",
    "    \n",
    "#     return train_x, test_x, train_y, test_y, scale, low \n",
    "\n",
    "    return train_x, test_x, train_y, test_y, mean_y_train, std_y_train\n",
    "\n",
    "split_data(x_[2], y_[2], test_split=0.1, seed=1, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bottom-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP(Module):\n",
    "    def __init__(self, likelihood, model, num_data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.likelihood = likelihood\n",
    "        self.num_data = num_data\n",
    "        self.beta = beta\n",
    "\n",
    "    def _log_likelihood_term(self, variational_dist_f, target, **kwargs):\n",
    "        return self.likelihood.expected_log_prob(target, variational_dist_f, **kwargs).sum(-1)\n",
    "    \n",
    "    def forward(self, approximate_dist_f, target, **kwargs):\n",
    "        num_batch = approximate_dist_f.event_shape[0]\n",
    "        log_likelihood = self._log_likelihood_term(approximate_dist_f, target, **kwargs).div(num_batch)\n",
    "        kl_divergence = self.model.variational_strategy.kl_divergence().div(self.num_data / self.beta)\n",
    "        \n",
    "        # Add any additional registered loss terms\n",
    "        added_loss = torch.zeros_like(log_likelihood)\n",
    "        had_added_losses = False\n",
    "        for added_loss_term in self.model.added_loss_terms():\n",
    "            added_loss.add_(added_loss_term.loss())\n",
    "            had_added_losses = True\n",
    "        \n",
    "        log_prior = torch.zeros_like(log_likelihood)\n",
    "        for name, module, prior, closure, _ in self.named_priors():\n",
    "            log_prior.add_(prior.log_prob(closure(module)).sum().div(self.num_data))\n",
    "\n",
    "        return log_likelihood - kl_divergence + log_prior - added_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "opponent-wells",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultivariateNormal(loc: torch.Size([51]))\n",
      "torch.Size([51, 13])\n",
      "torch.Size([51])\n",
      "pred_double: 2.1274304389953613\n",
      "scaled_pred: 42.18560028076172\n",
      "y_test: 37.599998474121094\n",
      "time: 0.007792999999999495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5145), tensor(2.7270))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svgp(x, y, training_iter, test_split, seed, printout):\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    start = time.process_time()\n",
    "    train_x, test_x, train_y, test_y, loc, scale = split_data(x, y, test_split, seed, norm=True)\n",
    "    end = time.process_time()\n",
    "    \n",
    "    num_inducing = 200\n",
    "    class GPModel(gpytorch.models.ApproximateGP):\n",
    "        def __init__(self, inducing_points):\n",
    "            variational_distribution = CholeskyVariationalDistribution(inducing_points.size(0))\n",
    "            variational_strategy = VariationalStrategy(self, inducing_points, variational_distribution, learn_inducing_locations=True)\n",
    "            super(GPModel, self).__init__(variational_strategy)\n",
    "            self.mean_module = gpytorch.means.ZeroMean()\n",
    "            self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "        def forward(self, x):\n",
    "            mean_x = self.mean_module(x)\n",
    "            covar_x = self.covar_module(x)\n",
    "            return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    inducing_points = train_x[:num_inducing]\n",
    "#         inducing_points = np.random.choice(train_x, size=num_inducing, replace=False)\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = GPModel(inducing_points=inducing_points)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    params = model.parameters()\n",
    "        \n",
    "    optimizer = torch.optim.Adam(params, lr=0.1)\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=train_y.size(0))\n",
    "\n",
    "    for i in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(train_x)\n",
    "        train_res_pred = gpytorch.distributions.MultivariateNormal(train_pred.mean, train_pred._covar)\n",
    "        \n",
    "        lld = -mll(train_pred, train_y)\n",
    "        lld.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        preds1 = model(test_x)\n",
    "        observed_pred = preds1\n",
    "\n",
    "        scaled_pred = gpytorch.distributions.MultivariateNormal(observed_pred.mean*scale + loc, observed_pred._covar*scale**2)\n",
    "        \n",
    "        lld = likelihood.log_marginal(test_y, scaled_pred).mean()\n",
    "    \n",
    "    \n",
    "    raw_rmse = torch.sqrt(torch.mean(torch.pow((scaled_pred.mean - test_y) , 2)))\n",
    "    \n",
    "    if printout:\n",
    "        print(observed_pred)\n",
    "        print(test_x.size())\n",
    "        print(test_y.size())\n",
    "        print('pred_double: {}'.format(observed_pred.mean[0]))\n",
    "        print('scaled_pred: {}'.format(scaled_pred.mean[0]))\n",
    "        print('y_test: {}'.format(test_y[0]))\n",
    "        print('time: {}'.format(end-start))\n",
    "\n",
    "    \n",
    "    return lld, raw_rmse\n",
    "\n",
    "training_iter = 100\n",
    "test_split = 0.1\n",
    "seed = 5\n",
    "printout=True\n",
    "\n",
    "svgp(x_[0], y_[0], training_iter, test_split, seed, printout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "patent-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset :boston\n",
      "loss: (-3.682078, -3.7304123408918355, -3.633743428456309), std:0.12726639211177826\n",
      "raw_rmse: (9.002504, 8.714967297232654, 9.290041400277111), std:0.7570955753326416\n",
      "Time: (0.1730533666666659, 0.15893877244856397, 0.18716796088476784) seconds, std:0.03716424526834373\n",
      "------------------------------------\n",
      "Dataset :concrete\n",
      "loss: (-4.2178626, -4.254858240808667, -4.180866971288501), std:0.09741086512804031\n",
      "raw_rmse: (15.804794, 15.39264671296252, 16.216941910084355), std:1.0851998329162598\n",
      "Time: (0.23534340000000023, 0.22723755977230176, 0.2434492402276987) seconds, std:0.021342975198099894\n",
      "------------------------------------\n",
      "Dataset :yacht\n",
      "loss: (-4.0810246, -4.1531010019995405, -4.008948291518526), std:0.18977968394756317\n",
      "raw_rmse: (13.791112, 12.860289758794416, 14.721934133417498), std:2.4508891105651855\n",
      "Time: (0.12385276666666697, 0.12040934334730508, 0.12729618998602887) seconds, std:0.00906666014098911\n",
      "------------------------------------\n",
      "Dataset :wine\n",
      "loss: (-1.2541951, -1.2678360553929413, -1.2405541328242218), std:0.03591715544462204\n",
      "raw_rmse: (0.78029114, 0.7597274479066701, 0.8008548322523265), std:0.0541449598968029\n",
      "Time: (0.40607176666666667, 0.39747252286023455, 0.4146710104730988) seconds, std:0.022642124952813945\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "# n = len(d)\n",
    "n_dataset = [0,1,2,3] # max 4\n",
    "itr = 30\n",
    "\n",
    "for j in n_dataset:\n",
    "    res[j] = {}\n",
    "    a_1, a_2, a_3, a_4, t, a_5 = [], [], [], [], [], []\n",
    "    \n",
    "    start = time.process_time()\n",
    "    for i in range(itr):\n",
    "        start = time.process_time()\n",
    "        loss, raw_rmse = svgp(\n",
    "            x_[j], y_[j], training_iter=1, \n",
    "            test_split=0.1, \n",
    "            seed=i, printout=False)\n",
    "        end = time.process_time()\n",
    "        \n",
    "        t.append(end-start)\n",
    "        a_1.append(loss)\n",
    "        a_2.append(raw_rmse)\n",
    "        \n",
    "    res[j]['a_1'] = a_1\n",
    "    res[j]['a_2'] = a_2\n",
    "    \n",
    "    \n",
    "    print('Dataset :{}'.format(datasets[j]))\n",
    "    print('loss: {}, std:{}'.format(mean_confidence_interval(a_1), np.std(a_1)))\n",
    "    print('raw_rmse: {}, std:{}'.format(mean_confidence_interval(a_2), np.std(a_2)))\n",
    "    print('Time: {} seconds, std:{}'.format(mean_confidence_interval(t), np.std(t)))\n",
    "    print('------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-cream",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
